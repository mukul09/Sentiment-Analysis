{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "7a739619868a940e5672a3cf28c51c96a79333d2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from nltk.corpus import stopwords\n",
    "#pd.options.display.max_rows = 999\n",
    "from textblob import TextBlob\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "f03463bfeb90749c85b0c678c94f5f1bfbe967d3"
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test.csv')\n",
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "0332eeba6208062f332a8ebd8206c68d3b768fdf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>#fingerprint #Pregnancy Test https://goo.gl/h1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Finally a transparant silicon case ^^ Thanks t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>We love this! Would you go? #talk #makememorie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>I'm wired I know I'm George I was made that wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>What amazing service! Apple won't even talk to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0  #fingerprint #Pregnancy Test https://goo.gl/h1...\n",
       "1   2      0  Finally a transparant silicon case ^^ Thanks t...\n",
       "2   3      0  We love this! Would you go? #talk #makememorie...\n",
       "3   4      0  I'm wired I know I'm George I was made that wa...\n",
       "4   5      1  What amazing service! Apple won't even talk to..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "4fbebbde1d041ac7ebdd130545c7a4b2353bf606"
   },
   "outputs": [],
   "source": [
    "df['length']=df['tweet'].apply(lambda x: len(x.split(' ')))\n",
    "#df.head()\n",
    "df_test['length']=df_test['tweet'].apply(lambda x: len(x.split(' ')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "a3d7f3d359cb06c35301f3c76efa239e1ad90f97"
   },
   "outputs": [],
   "source": [
    "df['lenChar']=df['tweet'].apply(lambda x: len(x))\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "41f8e97d60b82dbfae1cfb54faa6e1747aa57fbf"
   },
   "outputs": [],
   "source": [
    "df['avg_len']=df['lenChar']/df['length']\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "5ec72c3f24623a1630a0cb47beb1244f50f13f11"
   },
   "outputs": [],
   "source": [
    "stop_words=stopwords.words('english')\n",
    "df['#_stopwords']=df['tweet'].apply(lambda x: len([y for y in x.split(' ') if y in stop_words]))\n",
    "#df.head()\n",
    "df_test['#_stopwords']=df_test['tweet'].apply(lambda x: len([y for y in x.split(' ') if y in stop_words]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "7fdd43af10f8cd41b4b3013023d8f2c54ef58fa2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['#_numerics']=df['tweet'].apply(lambda x: len([y for y in x.split(' ') if y.isdigit()]))\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "be7f00360663e808fa7720ee551f1f9f11bd3cf0"
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "df['tweet']=df['tweet'].apply(lambda x: x.lower())\n",
    "#df.head()\n",
    "df_test['tweet']=df_test['tweet'].apply(lambda x: x.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "84a38b191969e0d2be2fdc1e994190a503a506c2"
   },
   "outputs": [],
   "source": [
    "df['tweet']=df['tweet'].str.replace('[^\\w\\s]','')\n",
    "#df.head()\n",
    "df_test['tweet']=df_test['tweet'].str.replace('[^\\w\\s]','')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "6f4c24a5f79509b4a06840ac4ceb282d1808a0bd"
   },
   "outputs": [],
   "source": [
    "df['tweet']=df['tweet'].apply(lambda x: ' '.join(y for y in x.split(' ') if y not in stop_words))\n",
    "#df.head()\n",
    "df_test['tweet']=df_test['tweet'].apply(lambda x: ' '.join(y for y in x.split(' ') if y not in stop_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "ffad7b7e72a05c9f3ae7cc8dd27e842431d6cc5d"
   },
   "outputs": [],
   "source": [
    "freq=pd.Series(' '.join(df['tweet']).split(' ')).value_counts()\n",
    "freq_test=pd.Series(' '.join(df_test['tweet']).split(' ')).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "874df068157c5f21b7a3954161eaf536e064758a"
   },
   "outputs": [],
   "source": [
    "freqent_words=freq[1:3]\n",
    "freqent_words=list(freqent_words.index)\n",
    "df['tweet']=df['tweet'].apply(lambda x: ' '.join(y for y in x.split(' ') if y not in freqent_words))\n",
    "#df.head()\n",
    "freqent_words_test=freq_test[1:3]\n",
    "freqent_words_test=list(freqent_words_test.index)\n",
    "df_test['tweet']=df_test['tweet'].apply(lambda x: ' '.join(y for y in x.split(' ') if y not in freqent_words_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "32e1df4d5c738f56b1269d11725a24eadb581c87"
   },
   "outputs": [],
   "source": [
    "rare_words=freq[freq==1]\n",
    "rare_words=list(rare_words.index)\n",
    "df['tweet']=df['tweet'].apply(lambda x: ' '.join(y for y in x.split(' ') if y not in rare_words))\n",
    "#df.head()\n",
    "rare_words_test=freq_test[freq_test==1]\n",
    "rare_words_test=list(rare_words_test.index)\n",
    "df_test['tweet']=df_test['tweet'].apply(lambda x: ' '.join(y for y in x.split(' ') if y not in rare_words_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "e901b9873df1917949bd31b33010cf75f4829687"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from nltk.stem import WordNetLemmatizer\\nlemmatizer = WordNetLemmatizer()\\ndf[\\'tweet\\'] = df[\\'tweet\\'].apply(lambda x: \" \".join([lemmatizer.lemmatize(x) for word in x.split()]))\\ndf[\\'tweet\\'].head()'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df['tweet'] = df['tweet'].apply(lambda x: \" \".join([lemmatizer.lemmatize(x) for word in x.split()]))\n",
    "df['tweet'].head()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "666aaf56aaa270bbae0cf45688a559f44db19db9"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(max_features=1000, lowercase=True, analyzer='word',stop_words= 'english',ngram_range=(1,1))\n",
    "vect = tfidf.fit_transform(df['tweet'])\n",
    "v=vect.toarray()\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=1000, lowercase=True, analyzer='word',stop_words= 'english',ngram_range=(1,1))\n",
    "vect_test = tfidf.fit_transform(df_test['tweet'])\n",
    "v_test=vect_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "ff1fe6c2f2cf17c782f22e997454a7ab23920b60"
   },
   "outputs": [],
   "source": [
    "#print(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "f32d01ca7b2c26a29d7c517bad5a12c7cd994a24"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow = CountVectorizer(lowercase=True,analyzer = \"word\")\n",
    "c_bow = bow.fit_transform(df['tweet'])\n",
    "c=c_bow.toarray()\n",
    "\n",
    "bow = CountVectorizer(lowercase=True,analyzer = \"word\")\n",
    "c_bow_test = bow.fit_transform(df_test['tweet'])\n",
    "c_test=c_bow_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "dcec030db32fa705c132fe20242fcc88a001f244"
   },
   "outputs": [],
   "source": [
    "#print(c_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "63f64f376c1e66f92ef1c05696b9f64b90f7086d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "'''X_train, X_test, y_train, y_test  = train_test_split(\n",
    "        v, \n",
    "        df['label'],\n",
    "        train_size=0.80, \n",
    "        random_state=1234)'''\n",
    "\n",
    "X_train=v\n",
    "y_train=df['label']\n",
    "X_test=v_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "c814f21adc660cc93ef1b81c4591ad384b330064"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.linear_model import LogisticRegression\\nlog_model = LogisticRegression()\\nlog_model = log_model.fit(X=X_train, y=y_train)\\ny_pred = log_model.predict(X_test)\\n#accuracy_score(y_test, predict)'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.linear_model import LogisticRegression\n",
    "log_model = LogisticRegression()\n",
    "log_model = log_model.fit(X=X_train, y=y_train)\n",
    "y_pred = log_model.predict(X_test)\n",
    "#accuracy_score(y_test, predict)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "ec1e36d5df6943e601d24f638cbbee2bb6832ac7"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest=RandomForestClassifier(n_estimators=58)\n",
    "random_forest.fit(X_train, y_train)\n",
    "predict=random_forest.predict(X_test)\n",
    "#accuracy_score(y_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "d35f04fc8aaa6d9a636f7bd6f24255a9b0f16b04"
   },
   "outputs": [],
   "source": [
    "pred=pd.Series(predict)\n",
    "pred.to_csv('prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a28d6b09fa42bb842aeffb39fb435975e115fbd7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6cb367b4845b7508031e0eb64040d0ffc008216d",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
